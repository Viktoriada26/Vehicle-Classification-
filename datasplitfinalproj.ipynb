{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0eee77b6-0a69-4470-8db2-f769f4181343",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3315f1-6a25-4823-b128-acfb2da96bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unzipping completed!\n",
      "Extracted files and directories: ['.bash_logout', '.bash_profile', '.bashrc', '.emacs', '.local', '.ipython', '.jupyter', '.bash_history', '.nv', '.ipynb_checkpoints', '.ssh', '.lesshst', '.python_history', 'ThaiOCR-TrainigSet-Link', 'training_data.txt', 'validation_data.txt', 'test_data.txt', 'validation.py', 'traintestvalid_split.py', 'trainingtestvalidjupyter.ipynb', 'ThaiEng_model.pth', 'ThaiEnglish_model.pth', 'training.ipynb', 'args.py', 'dataset.py', 'datasplit.py', 'untitled1.py', 'test.py', 'archive (1).zip', 'modeltraining.py', 'model.py', 'train.py', '__pycache__', 'splitdata.py', 'Untitled.ipynb', 'datasplitproject.ipynb', 'dataset', 'Untitled Folder']\n"
     ]
    }
   ],
   "source": [
    "zip_file = 'archive (1).zip'\n",
    "\n",
    "extract_to = os.getcwd()\n",
    "\n",
    "with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_to)\n",
    "\n",
    "print(\"Unzipping completed!\")\n",
    "\n",
    "\n",
    "extracted_files = os.listdir(extract_to)\n",
    "print(\"Extracted files and directories:\", extracted_files) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8eb81f73-487a-4844-8b19-e12f1ccd66f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de4dfcb-3b3f-4184-a1c4-3b2edce46239",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29bbe9bd-8634-4b26-920b-aa9c7f320302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training files for each class:\n",
      "Category: bus, Files: 1315\n",
      "Category: car, Files: 810\n",
      "Category: motorcycle, Files: 1069\n",
      "Category: train, Files: 1319\n",
      "Category: truck, Files: 908\n",
      "\n",
      "Validation files for each class:\n",
      "Category: bus, Files: 176\n",
      "Category: car, Files: 106\n",
      "Category: motorcycle, Files: 145\n",
      "Category: train, Files: 182\n",
      "Category: truck, Files: 100\n",
      "\n",
      "Test files for each class:\n",
      "Category: bus, Files: 180\n",
      "Category: car, Files: 107\n",
      "Category: motorcycle, Files: 139\n",
      "Category: train, Files: 182\n",
      "Category: truck, Files: 100\n",
      "Files saved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def load_data(train_dir, test_dir, val_dir):\n",
    "    \"\"\"Loads the paths from the presplitted dataset \n",
    "\n",
    "    Args:\n",
    "        train_dir (str): path to the training directory  \n",
    "        test_dir (str): path to the test directory\n",
    "        val_dir (str): path to the validation directory \n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple of 3 dictionaries where each vehicle classes is the key and\n",
    "        the values is list with all the images paths\n",
    "    \"\"\"\n",
    "    train_files = {}\n",
    "    val_files = {}\n",
    "    test_files = {}\n",
    "    \n",
    "    categories = os.listdir(train_dir)\n",
    "    \n",
    "    for category in categories:\n",
    "        category_train_path = os.path.join(train_dir, category)\n",
    "        category_test_path = os.path.join(test_dir, category)\n",
    "        category_val_path = os.path.join(val_dir, category)\n",
    "        \n",
    "        if not os.path.isdir(category_train_path):\n",
    "            continue\n",
    "        \n",
    "        train_files[category] = []\n",
    "        for f in os.listdir(category_train_path):\n",
    "            file_path = os.path.join(category_train_path, f)\n",
    "            if os.path.isfile(file_path):\n",
    "                train_files[category].append(file_path)\n",
    "\n",
    "        \n",
    "        if os.path.isdir(category_test_path):\n",
    "            test_files[category] = []\n",
    "            for f in os.listdir(category_test_path):\n",
    "                file_path = os.path.join(category_test_path, f)\n",
    "                if os.path.isfile(file_path):\n",
    "                    test_files[category].append(file_path)\n",
    "        \n",
    "        if os.path.isdir(category_val_path):\n",
    "            val_files[category] = []\n",
    "            for f in os.listdir(category_val_path):\n",
    "                file_path = os.path.join(category_val_path, f)\n",
    "                if os.path.isfile(file_path):\n",
    "                    val_files[category].append(file_path)\n",
    "    return train_files, val_files, test_files\n",
    "\n",
    "train_dir = './dataset/train/'\n",
    "test_dir = './dataset/test/'\n",
    "val_dir = './dataset/validation/'\n",
    "train_files, val_files, test_files = load_data(train_dir, test_dir, val_dir)\n",
    "\n",
    "print(\"Training files for each class:\")\n",
    "for category, files in train_files.items():\n",
    "    print(f\"Category: {category}, Files: {len(files)}\")\n",
    "\n",
    "print(\"\\nValidation files for each class:\")\n",
    "for category, files in val_files.items():\n",
    "    print(f\"Category: {category}, Files: {len(files)}\")\n",
    "\n",
    "print(\"\\nTest files for each class:\")\n",
    "for category, files in test_files.items():\n",
    "    print(f\"Category: {category}, Files: {len(files)}\")\n",
    "\n",
    "def save_to_txt(file_dict, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        for category, files in file_dict.items():\n",
    "            for file in files:\n",
    "                f.write(f\"{file}\\n\")\n",
    "\n",
    "save_to_txt(train_files, 'training_data.txt')\n",
    "save_to_txt(val_files, 'validation_data.txt')\n",
    "save_to_txt(test_files, 'testing_data.txt')\n",
    "\n",
    "print(\"Files saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e523332b-0088-4746-aacb-ea10bd0b27c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsampled Training per class:\n",
      "Category: bus, Files: 1319\n",
      "Category: car, Files: 1319\n",
      "Category: motorcycle, Files: 1319\n",
      "Category: train, Files: 1319\n",
      "Category: truck, Files: 1319\n",
      "\n",
      "Validation files per class:\n",
      "Category: bus, Files: 176\n",
      "Category: car, Files: 106\n",
      "Category: motorcycle, Files: 145\n",
      "Category: train, Files: 182\n",
      "Category: truck, Files: 100\n",
      "\n",
      "Test files per class:\n",
      "Category: bus, Files: 180\n",
      "Category: car, Files: 107\n",
      "Category: motorcycle, Files: 139\n",
      "Category: train, Files: 182\n",
      "Category: truck, Files: 100\n",
      "Upsampled train saved\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.utils import resample\n",
    "\n",
    "def upsample_category(file_list, target_size):\n",
    "    \"\"\"Upsamples a list of file paths in order to reach the target size by random \n",
    "    upsampling with sklearn resample \n",
    "\n",
    "\n",
    "    Args:\n",
    "        file_list (list): List of images paths for each vehicle\n",
    "        target_size (int): Target number of samples that the upsampling needs \n",
    "        to achieve for each class\n",
    "\n",
    "    Returns:\n",
    "        list: A new list of images paths which includes now the upsampled images\n",
    "        in order to get the target size. \n",
    "    \"\"\"\n",
    "    \n",
    "    return resample(file_list, replace=True, n_samples=target_size, random_state=42)\n",
    "\n",
    "def balance_training_data(train_files):\n",
    "    \"\"\"creates an upsampled training dataset where all vehicles have the same number\n",
    "    of images. \n",
    "\n",
    "    Args:\n",
    "        train_files (dict): The train files have as a key the vehicle name and as a \n",
    "        value the number of images. \n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where all classes are balanced now\n",
    "    \"\"\"\n",
    "    max_train_size = 0\n",
    "    for category in train_files:\n",
    "        if len(train_files[category]) > max_train_size:\n",
    "            max_train_size = len(train_files[category])\n",
    "    \n",
    "    for category in train_files:\n",
    "        if len(train_files[category]) < max_train_size:\n",
    "            train_files[category] = upsample_category(train_files[category], max_train_size)\n",
    "    \n",
    "    return train_files\n",
    "\n",
    "train_dir = './dataset/train/'\n",
    "test_dir = './dataset/test/'\n",
    "val_dir = './dataset/validation/'\n",
    "\n",
    "\n",
    "train_files, val_files, test_files = load_data(train_dir, test_dir, val_dir)\n",
    "\n",
    "train_files_balanced = balance_training_data(train_files)\n",
    "\n",
    "print(\"Upsampled Training per class:\")\n",
    "for category, files in train_files_balanced.items():\n",
    "    print(f\"Category: {category}, Files: {len(files)}\")\n",
    "\n",
    "print(\"\\nValidation files per class:\")\n",
    "for category, files in val_files.items():\n",
    "    print(f\"Category: {category}, Files: {len(files)}\")\n",
    "\n",
    "print(\"\\nTest files per class:\")\n",
    "for category, files in test_files.items():\n",
    "    print(f\"Category: {category}, Files: {len(files)}\")\n",
    "\n",
    "save_to_txt(train_files_balanced, 'balanced_training_data.txt')\n",
    "save_to_txt(val_files, 'validation_data.txt')\n",
    "save_to_txt(test_files, 'testing_data.txt')\n",
    "\n",
    "print(\"Upsampled train saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c613e6-b09f-47f3-8dce-7702e52c2f84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
